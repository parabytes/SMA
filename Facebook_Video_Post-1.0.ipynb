{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Functions-and-Classes\" data-toc-modified-id=\"Functions-and-Classes-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions and Classes</a></span></li><li><span><a href=\"#System-dependent-Configuration\" data-toc-modified-id=\"System-dependent-Configuration-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>System-dependent Configuration</a></span></li></ul></li><li><span><a href=\"#Collect-Data\" data-toc-modified-id=\"Collect-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Collect Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-the-Data-Collection-Environment\" data-toc-modified-id=\"Setup-the-Data-Collection-Environment-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Setup the Data Collection Environment</a></span></li><li><span><a href=\"#Collect-Facebook-Post-Data\" data-toc-modified-id=\"Collect-Facebook-Post-Data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Collect Facebook Post Data</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This playbook has been developed by the Discovery Lab, Applied Intelligence, Accenture Federal Services. @ 2019-2020\n",
    "<p> This playbook can harvest most data around a Facebook video post.</p>\n",
    "\n",
    "<p> <b>INPUT:</b> A Facebook video link (e.g., https://www.facebook.com/watch/?v=909234282742495). </p>\n",
    "\n",
    "<p> <b>OUTPUT</b> is written under data/raw in the format of FB_VIDEOPOST_{Scrape_DateTime}_{Video_Link}.csv </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "<p> The imports, function and class defintions, global variables, and system-dependent configuration are in this section. </p>\n",
    "\n",
    "<p> The system dependent configuration should be carefully reviewed and configured for each system (e.g., Linux vs. Windows, or the path of an external program) since the playbook will most likely fail without proper configuration. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This cell imports necessary Python modules and performs initial configuration\n",
    "\"\"\"\n",
    "\n",
    "### Data manipulation libraries\n",
    "# import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "\n",
    "### Visualization and Interaction\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "from IPython.display import set_matplotlib_formats, display, clear_output, HTML\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import VBox, HBox, Button, HTML, Label\n",
    "\n",
    "### Computation libraries \n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "### Graph analysis\n",
    "# import networkx as nx\n",
    "# import community\n",
    "\n",
    "### System related\n",
    "# import sys\n",
    "# import warnings;\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "### Datetime libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pytz import timezone\n",
    "\n",
    "### NLP dependencies\n",
    "# import spacy\n",
    "# from spacy.tokenizer import Tokenizer\n",
    "# nlp = spacy.load('en')\n",
    "# tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# from langdetect import detect\n",
    "\n",
    "### Scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "### Machine learning libraries\n",
    "# from sklearn import datasets\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "### Logging\n",
    "import logging \n",
    "logging.basicConfig(level=logging.INFO) # Initial setup\n",
    "\n",
    "#import spacy\n",
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines global variables and parameters used throughout the playbook\n",
    "\"\"\"\n",
    "\n",
    "# Set this to True if you want to watch Selenium scrape pages\n",
    "WATCH_SCRAPING = True\n",
    "\n",
    "# Set this to True if you want to use incognito mode\n",
    "USE_INCOGNITO = True\n",
    "\n",
    "# The data is written \n",
    "RAW_DATA_DIRECTORY = Path(\"../data/raw/\")\n",
    "\n",
    "# Setup logging level\n",
    "LOGGING_LEVEL = logging.INFO \n",
    "logging.basicConfig(level=LOGGING_LEVEL)\n",
    "\n",
    "# Maximum number of scrolls\n",
    "MAX_NUMBER_OF_SCROLLS = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines functions and classes used throughout the playbook\n",
    "\"\"\"\n",
    "\n",
    "# Scraper columns\n",
    "COLUMNS = [\"datetime_of_post\", \n",
    "           \"type_of_post\", \n",
    "           \"commenter_profile_pic\", \n",
    "           \"commenter_name\", \n",
    "           \"comment_text\", \n",
    "           \"comment_engagements\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System-dependent Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines system-dependent configuration such as those different in Linux vs. Windows\n",
    "\"\"\"\n",
    "\n",
    "# Get the system information from the OS\n",
    "PLATFORM_SYSTEM = platform.system()\n",
    "\n",
    "# Darwin is macOS\n",
    "if PLATFORM_SYSTEM == \"Darwin\":\n",
    "    EXECUTABLE_PATH = Path(\"../dependencies/chromedriver\")\n",
    "elif PLATFORM_SYSTEM == \"Windows\":\n",
    "    EXECUTABLE_PATH = Path(\"../dependencies/chromedriver.exe\")\n",
    "else:\n",
    "    logging.critical(\"Chromedriver not found or Chromedriver is outdated...\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Data Collection Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Chrome could not be launched. Check if EXECUTABLE_PATH is configured correctly. If it is, check if the Chromedriver supports the version of the browser.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Setup the scraper\n",
    "\"\"\"\n",
    "\n",
    "# Create the driver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "if not WATCH_SCRAPING:\n",
    "    chrome_options.add_argument('--headless')\n",
    "\n",
    "if USE_INCOGNITO:\n",
    "    chrome_options.add_argument('--incognito')\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome(options=chrome_options, executable_path=EXECUTABLE_PATH)\n",
    "    logging.info(\"Chrome launched\")\n",
    "except:\n",
    "    logging.critical(\"Chrome could not be launched. Check if EXECUTABLE_PATH is configured correctly. If it is, check if the Chromedriver supports the version of the browser.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Facebook Post Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a675cbf896e24d37b692178d1cde17df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='text-align: center;'> Scrape a Facebook Post </h2>\"), HBox(children=(Lab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b7c5c49db14d87849738a159af59e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This cell retrieves page posts and comments, for a given page.\n",
    "\"\"\"\n",
    "\n",
    "text = widgets.Text(description=\"\", width=400)\n",
    "button = widgets.Button(description=\"Start!\")\n",
    "fb_selection = HBox([Label(value=\"Enter the full URL of the Facebook post:\"), text, button])\n",
    "display(VBox([HTML(\"<h2 style='text-align: center;'> Scrape a Facebook Post </h2>\"), fb_selection]))\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "comment_array_of_arrays = []\n",
    "comment_array = []\n",
    "text_of_page_arrays = []\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        initial_page = text.value\n",
    "        # posts_page = \"https://www.facebook.com/\" + str(text.value) + \"/posts_to_page?ref=page_internal\"\n",
    "        print(\"Retrieving posts and comments from \" + str(initial_page))\n",
    " \n",
    "        try:\n",
    "            driver.get(initial_page)\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            logging.info(\"Error retrieving the page. Try again.\")\n",
    "            \n",
    "        # Go to the end of the page and make sure the pop-up appears\n",
    "        driver.execute_script(\"window.scrollTo(0, 10000)\") \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Get rid of the pop-up\n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"_3j0u\").click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            logging.info(\"The popup page is not there.\")        \n",
    " \n",
    "        # Go to the begining of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, 0)\") \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Open the comments\n",
    "        open_comment_found_and_clicked = False\n",
    "        scroll_count = 1\n",
    "        while not open_comment_found_and_clicked:\n",
    "            try:\n",
    "                driver.find_element_by_class_name(\"_3hg-\").click()\n",
    "                print(\"Comments found and clicked -- _3hg-\")\n",
    "                open_comment_found_and_clicked = True\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print(\"Comment still not found -- _3hg-\")\n",
    "                driver.execute_script(\"window.scrollTo(0, {0})\".format(scroll_count * 100))             \n",
    "                scroll_count += 1\n",
    "                time.sleep(1)        \n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, {0})\".format((scroll_count + 7) * 100))             \n",
    "\n",
    "        driver.find_element_by_class_name(\"_7a99\").click()\n",
    "        driver.find_elements_by_class_name(\"_54nc\")[2].click()\n",
    "        \n",
    "        # Hit the bottom and no more comments\n",
    "        \n",
    "        while scroll_count <= MAX_NUMBER_OF_SCROLLS:\n",
    "            try:\n",
    "                driver.find_element_by_class_name(\"_4sxc\").click()\n",
    "                print(\"Comments found and clicked -- _4sxc\")\n",
    "                open_comment_found_and_clicked = True\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print(\"Comment still not found -- _4sxc\")\n",
    "                driver.execute_script(\"window.scrollTo(0, {0})\".format(scroll_count * 100))             \n",
    "                scroll_count += 1\n",
    "                time.sleep(1) \n",
    "            \n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        comment_wrappers = soup.find(\"ul\", class_=\"_7a9a\").find_all(\"li\", recursive=False)\n",
    "        print(\"number of content_wrappers: \" + str(len(comment_wrappers)))\n",
    "        comment_row = []\n",
    "                        \n",
    "        for comment in comment_wrappers:\n",
    "            # keep original comment\n",
    "            original_comment = comment\n",
    "            comment = comment.find_all(\"div\", class_=\"_4eek\")\n",
    "            comment = comment[0]\n",
    "            comment_data = {\"datetime_of_post\": None,\n",
    "                \"type_of_post\": \"comment\",\n",
    "                \"commenter_profile_pic\": None,\n",
    "                \"commenter_name\": None,\n",
    "                \"comment_text\": None,\n",
    "                \"comment_engagements\": 0\n",
    "                }\n",
    "\n",
    "            try:\n",
    "                comment_data[\"datetime_of_post\"] = comment.find(\"ul\", class_=\"_6coi\").find(\"abbr\")[\"data-tooltip-content\"]\n",
    "            except:\n",
    "                logging.info(\"No datetime found\")\n",
    "                \n",
    "            try:\n",
    "                comment_data[\"comment_engagements\"] = comment.find(\"div\", class_=\"_6cuq\").find(text=True, recursive=True)\n",
    "            except:\n",
    "                logging.info(\"No engagements found for this link\")\n",
    "                \n",
    "            # Find commenter name\n",
    "            # Sometimes it is in \"a\", sometimes it is in \"span\"\n",
    "            try:\n",
    "                if comment.find(\"a\", class_=\"_6qw4\"):\n",
    "                    comment_data[\"commenter_name\"] = comment.find(\"a\", class_=\"_6qw4\").find(text=True, recursive=True)\n",
    "\n",
    "                if comment.find(\"span\", class_=\"_6qw4\"):\n",
    "                    comment_data[\"commenter_name\"] = comment.find(\"span\", class_=\"_6qw4\").find(text=True, recursive=True)\n",
    "            except:\n",
    "                logging.info(\"Could not find commenter name.\")\n",
    "\n",
    "            # Get commenter profile picture\n",
    "            try:\n",
    "                comment_data[\"commenter_profile_pic\"] = comment.find(\"img\")[\"src\"]\n",
    "            except:\n",
    "                logging.info(\"Could not find commenter image.\")\n",
    "\n",
    "            # Get comment\n",
    "            try:\n",
    "                if comment.find(\"span\", {\"dir\": \"ltr\"}):\n",
    "                    comment_data[\"comment_text\"] = comment.find(\"span\", {\"dir\": \"ltr\"}).find(text=True, recursive=True)                                                              \n",
    "                if comment.find(\"span\", {\"dir\": \"rtl\"}):\n",
    "                    comment_data[\"comment_text\"] = comment.find(\"span\", {\"dir\": \"rtl\"}).find(text=True, recursive=True)                                                              \n",
    "\n",
    "            except:\n",
    "                logging.info(\"Could not find comment.\")\n",
    "\n",
    "            comment_row.append(comment_data)\n",
    "            \n",
    "            # Looking for replies\n",
    "            replies = original_comment.find(\"div\", class_=\"_7a9h\")\n",
    "            if replies:\n",
    "                replies = replies.find(\"ul\", recursive=False)\n",
    "                if replies:\n",
    "                    replies = replies.find_all(\"li\", recursive=False)\n",
    "                    \n",
    "            if replies:\n",
    "                for reply in replies:\n",
    "                    reply = reply.find_all(\"div\", class_=\"_4eek\")\n",
    "                    reply = reply[0]\n",
    "                    comment_data = {\"datetime_of_post\": None,\n",
    "                        \"type_of_post\": \"reply\",\n",
    "                        \"commenter_profile_pic\": None,\n",
    "                        \"commenter_name\": None,\n",
    "                        \"comment_text\": None,\n",
    "                        \"comment_engagements\": 0\n",
    "                        }\n",
    "\n",
    "                    try:\n",
    "                        comment_data[\"datetime_of_post\"] = comment.find(\"ul\", class_=\"_6coi\").find(\"abbr\")[\"data-tooltip-content\"]\n",
    "                    except:\n",
    "                        logging.info(\"No datetime found\")\n",
    "                        \n",
    "                    try:\n",
    "                        comment_data[\"comment_engagements\"] = reply.find(\"div\", class_=\"_6cuq\").find(text=True, recursive=True)\n",
    "                    except:\n",
    "                        logging.info(\"No engagements found for this link\")\n",
    "                        \n",
    "                    # Find commenter name\n",
    "                    # Sometimes it is in \"a\", sometimes it is in \"span\"\n",
    "                    try:\n",
    "                        if reply.find(\"a\", class_=\"_6qw4\"):\n",
    "                            comment_data[\"commenter_name\"] = reply.find(\"a\", class_=\"_6qw4\").find(text=True, recursive=True)\n",
    "\n",
    "                        if reply.find(\"span\", class_=\"_6qw4\"):\n",
    "                            comment_data[\"commenter_name\"] = reply.find(\"span\", class_=\"_6qw4\").find(text=True, recursive=True)\n",
    "                    except:\n",
    "                        logging.info(\"Could not find commenter name.\")\n",
    "\n",
    "                    # Get commenter profile picture\n",
    "                    try:\n",
    "                        comment_data[\"commenter_profile_pic\"] = reply.find(\"img\")[\"src\"]\n",
    "                    except:\n",
    "                        logging.info(\"Could not find commenter image.\")\n",
    "\n",
    "                    # Get comment: Check whether the language is right to left or vice versa\n",
    "                    try:\n",
    "                        if reply.find(\"span\", {\"dir\": \"ltr\"}):\n",
    "                            comment_data[\"comment_text\"] = reply.find(\"span\", {\"dir\": \"ltr\"}).find(text=True, recursive=True)                                                              \n",
    "                        if reply.find(\"span\", {\"dir\": \"rtl\"}):\n",
    "                            comment_data[\"comment_text\"] = reply.find(\"span\", {\"dir\": \"rtl\"}).find(text=True, recursive=True)                                                              \n",
    "                    except:\n",
    "                        logging.info(\"Could not find comment.\")\n",
    "                        \n",
    "                    comment_row.append(comment_data)\n",
    "            \n",
    "            \n",
    "        df_comments = pd.DataFrame.from_dict(comment_row)\n",
    "        file_name = \"FB_VIDEOPOST_\" + datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\") + \"_\" + initial_page.split(\"?v=\")[1] + \".csv\"\n",
    "        df_comments.to_csv(RAW_DATA_DIRECTORY / file_name , index=False, na_rep='None', columns=COLUMNS)\n",
    "        print(df_comments)\n",
    "        \n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-67517ff1ad72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Clean up the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Add post-processing steps here\n",
    "\"\"\"\n",
    "\n",
    "# Clean up the environment\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

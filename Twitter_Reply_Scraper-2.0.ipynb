{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Initialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Specify-Global-Variables\" data-toc-modified-id=\"Specify-Global-Variables-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Specify Global Variables</a></span></li><li><span><a href=\"#Functions-and-Classes\" data-toc-modified-id=\"Functions-and-Classes-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions and Classes</a></span></li><li><span><a href=\"#System-dependent-Configuration\" data-toc-modified-id=\"System-dependent-Configuration-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>System-dependent Configuration</a></span></li></ul></li><li><span><a href=\"#Data-Import-and-Preprocessing\" data-toc-modified-id=\"Data-Import-and-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Import and Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scrape-Twitter-Replies\" data-toc-modified-id=\"Scrape-Twitter-Replies-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Scrape Twitter Replies</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<p> This playbook scrapes Twitter replies for a given post. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "\n",
    "<p> The imports, function and class defintions, global variables, and system-dependent configuration are in this section. </p>\n",
    "\n",
    "<p> The system dependent configuration should be carefully reviewed and configured for each system (e.g., Linux vs. Windows, or the path of an external program) since the playbook will most likely fail without proper configuration. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### This cell imports necessary Python modules and performs initial configuration\n",
    "\n",
    "### Data manipulation libraries\n",
    "# import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "\n",
    "### Visualization and Interaction\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "from IPython.display import set_matplotlib_formats, display, clear_output, HTML\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import VBox, HBox, Button, HTML\n",
    "\n",
    "### Computation libraries \n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "### Graph analysis\n",
    "# import networkx as nx\n",
    "# import community\n",
    "\n",
    "### System related\n",
    "# import sys\n",
    "# import warnings;\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "### Datetime libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pytz import timezone\n",
    "\n",
    "### NLP dependencies\n",
    "# import spacy\n",
    "# from spacy.tokenizer import Tokenizer\n",
    "# nlp = spacy.load('en')\n",
    "# tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# from langdetect import detect\n",
    "\n",
    "### Scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "### Machine learning libraries\n",
    "# from sklearn import datasets\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "### Logging\n",
    "import logging \n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "#import spacy\n",
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell defines global variables and parameters used throughout the playbook\n",
    "\n",
    "# Make this True if you want to watch Selenium scrape pages\n",
    "WATCH_SCRAPING = True\n",
    "\n",
    "MAX_SCROLLS = 100\n",
    "\n",
    "RAW_DATA_DIRECTORY = \"../data/raw/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell defines functions and classes used throughout the playbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System-dependent Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell defines system-dependent configuration such as those different in Linux vs. Windows\n",
    "\n",
    "# Assuming a particular directory structure and a Linux-based system\n",
    "# As of Sep 2, 2019, the chromedriver is version 76.X\n",
    "EXECUTABLE_PATH = \"../WebDriver/chromedriver\"\n",
    "\n",
    "COLUMNS = [\"commenter_id\", \"comment_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Chrome launched\n"
     ]
    }
   ],
   "source": [
    "### Instagram hashtag or user to be scraped is entered in this step\n",
    "\n",
    "# Create the driver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "if not WATCH_SCRAPING:\n",
    "    chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--incognito')\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome(options=chrome_options, executable_path=EXECUTABLE_PATH)\n",
    "    logging.info(\"Chrome launched\")\n",
    "except:\n",
    "    logging.critical(\"Chrome could not be launched. Check if EXECUTABLE_PATH is configured correcely. If it is, check if the Chromedriver supports the version of the browser.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Twitter Replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2abb1d2d284b0cb109cff65a955c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Twitter link (whole link): '), Button(description='Retrieve', styleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a244d063b7ab40d9ab465678d09ec356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell retrieves page posts and comments, for a given page.\n",
    "\"\"\"\n",
    "text = widgets.Text(description=\"Twitter link (whole link): \", width=200)\n",
    "button = widgets.Button(description=\"Retrieve\")\n",
    "fb_selection = HBox([text, button])\n",
    "display(fb_selection)\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "comment_array_of_arrays = []\n",
    "comment_array = []\n",
    "text_of_page_arrays = []\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    global soup, comment_row, tweet_set, tweet_list, tweet_dict\n",
    "    tweet_list = []\n",
    "    tweet_set = set()\n",
    "    tweet_dict = dict()\n",
    "    with out:\n",
    "        clear_output()\n",
    "        initial_page = text.value\n",
    "        print(\"Retrieving posts and comments from \" + str(initial_page))\n",
    "        try:\n",
    "            driver.get(initial_page)\n",
    "            time.sleep(1)\n",
    "            scrolls = 0\n",
    "            \n",
    "            # conditions to check whether there are more tweets\n",
    "            prev_len = 0 \n",
    "            more_tweets = True\n",
    "            # menu = driver.find_element_by_xpath(\"//div[@data-testid='primaryColumn']\")\n",
    "            # ActionChains(driver).move_to_element(menu).click()\n",
    "            while scrolls < MAX_SCROLLS and more_tweets:\n",
    "                # ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "                driver.execute_script(\"window.scrollTo(0, \" + str(scrolls * 500) + \");\")\n",
    "                time.sleep(1)\n",
    "                scrolls += 1\n",
    "                # Britany's adds open the comments \n",
    "                \n",
    "                try:\n",
    "                    chrome_options2 = webdriver.ChromeOptions()\n",
    "                    chrome_options2.add_argument('--headless')\n",
    "                    chrome_options2.add_argument('--incognito')\n",
    "                    driver2 = webdriver.Chrome(options=chrome_options2, executable_path=EXECUTABLE_PATH)\n",
    "                    driver2.quit()  \n",
    "                    time.sleep(1)\n",
    "                    print(\"Starting parsing\")\n",
    "                    # TODO: Clicking takes the page to the top - need to find the right element to click\n",
    "                    tw_timeline = driver.find_element_by_xpath('//div[@aria-label=\"Timeline: Conversation\"]')\n",
    "                    \n",
    "                    # Click button\n",
    "                    try:\n",
    "                        all_buttons = driver.find_element_by_xpath('//div[@aria-label=\"Timeline: Conversation\"]').find_elements_by_xpath('//div[@role=\"button\"]')\n",
    "                        for a_button in all_buttons:\n",
    "                            text_array = BeautifulSoup(a_button.get_attribute(\"innerHTML\")).find_all(text=True, recursive=True)\n",
    "                            \n",
    "                            concat_text = \"\"\n",
    "                            \n",
    "                            for ta in text_array:\n",
    "                                concat_text += \" \" + ta\n",
    "                                \n",
    "                            if \"Show\" in concat_text:\n",
    "                                a_button.click()\n",
    "                                \n",
    "                    except:\n",
    "                        print(\"Button not found...\")\n",
    "                        \n",
    "                    # print(tw_timeline.get_attribute(\"innerHTML\"))\n",
    "                    tw_timeline = (tw_timeline.get_attribute(\"innerHTML\"))            \n",
    "                    #print(tw_timeline)\n",
    "                    # tweet_list.extend(tw_elements)\n",
    "                    # print(\"array\", len(tweet_list))\n",
    "                    tw_elements = BeautifulSoup(tw_timeline).find(\"div\").find_all(\"article\", recursive=True)\n",
    "                    for twe in tw_elements:\n",
    "                        tweet_set = tweet_set.union(twe)\n",
    "                        # tweet_dict.update({str(twe): None})\n",
    "                        tweet_list.append(twe)\n",
    "                        \n",
    "                    if scrolls % 4 == 3:\n",
    "                        if len(tweet_set) > prev_len:\n",
    "                            prev_len = len(tweet_set)                                \n",
    "                        else:\n",
    "                            more_tweets = False\n",
    "\n",
    "                            \n",
    "                    #print(\"current set\", len(tweet_set))\n",
    "                    #print(\"current list\", len(tweet_list))\n",
    "                    print(scrolls)\n",
    "                    print(\"---\")\n",
    "\n",
    "                    # driver.find_element_by_class_name(\"r-qvutc0\").click()            \n",
    "                except:\n",
    "                    print(\"Error in finding the element...\")\n",
    "                    time.sleep(1)\n",
    "                \n",
    "        except:\n",
    "            logging.info(\"Error retrieving the page. Try again.\")\n",
    "            \n",
    "        # An interaction with the browser is required to open up the tweets\n",
    "        # This is the easiest way\n",
    "        chrome_options2 = webdriver.ChromeOptions()\n",
    "        chrome_options2.add_argument('--headless')\n",
    "        chrome_options2.add_argument('--incognito')\n",
    "        driver2 = webdriver.Chrome(options=chrome_options2, executable_path=EXECUTABLE_PATH)\n",
    "        driver2.quit()  \n",
    "                \n",
    "        twitter_handle = re.compile(\n",
    "            '''\n",
    "            (?<=@)\n",
    "            ([\\w\\d_]+)       # username\n",
    "            ''',\n",
    "            re.UNICODE | re.VERBOSE)\n",
    "        \n",
    "        comment_row = []\n",
    "\n",
    "        for tw_element in tweet_list:\n",
    "            comment_data = {\"commenter_id\": None,\n",
    "                \"comment_text\": None\n",
    "            }\n",
    "            \n",
    "            soup_tw = tw_element.find(\"div\", class_=\"r-1mi0q7o\", recursive=True)\n",
    "\n",
    "            # Get user_id\n",
    "            try:\n",
    "                username_array = soup_tw.find_all(\"div\", class_=\"css-1dbjc4n\", recursive=False)[0].find_all(text=True, recursive=True)\n",
    "                concat_text = \"\"\n",
    "                for uax in username_array:\n",
    "                    concat_text += \" \" + uax\n",
    "                concat_text = concat_text.replace(\"\\n\", \" \")  \n",
    "                comment_data[\"commenter_id\"] = twitter_handle.findall(concat_text)[0]\n",
    "            except:\n",
    "                # Not all divs are \n",
    "                continue\n",
    "                \n",
    "            # Get the text\n",
    "            try:\n",
    "                text_array_pre = soup_tw.find_all(\"div\", class_=\"css-1dbjc4n\", recursive=False)[1]\n",
    "                initial_text = text_array_pre.find_all(\"div\", recursive=False)\n",
    "                text_array = initial_text[-3].find_all(text=True, recursive=True)\n",
    "                concat_text = \"\"\n",
    "                for tax in text_array:\n",
    "                    concat_text += \" \" + tax\n",
    "                concat_text = concat_text.replace(\"\\n\", \" \")\n",
    "                comment_data[\"comment_text\"] = concat_text\n",
    "            except:\n",
    "                pass\n",
    "            #print(soup.find_all(\"div\", class_=\"css-1dbjc4n\", recursive=False)[1].text)\n",
    "            #print(\"----\")\n",
    "            comment_row.append(comment_data)\n",
    "        \n",
    "\n",
    "        df_comments = pd.DataFrame.from_dict(comment_row)\n",
    "        \n",
    "        # Using list: the elements are duplicate\n",
    "        # using set solves the duplicate issue but it is not ordered\n",
    "        df_comments = df_comments.drop_duplicates()\n",
    "        df_comments.to_csv(\"TWITTER-POST-\" + initial_page.split(\"/\")[-1] + \"-\" + datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\") + \".csv\", index=False, na_rep='None', columns=COLUMNS)\n",
    "        print(\"Data scraping finished...\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Example status Twitter link: https://twitter.com/JZarif/status/1253698754575765515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=set([\"onur\", \"ena\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
